# AI Testing Configuration for CI/GitHub Actions
# This file provides fallback configurations for testing in environments
# where LM Studio, Ollama, or other AI providers may not be available

# Primary AI Provider Selection
ai.provider.primary=simple
ai.provider.fallback=true
ai.provider.timeout=10

# LM Studio Configuration (for local testing)
ai.llmstudio.enabled=false
ai.llmstudio.url=http://localhost:1234
ai.llmstudio.model=local-model
ai.llmstudio.timeout=30

# Ollama Configuration (for CI with Ollama)
ai.ollama.enabled=false
ai.ollama.url=http://localhost:11434
ai.ollama.model=tinyllama:1.1b
ai.ollama.timeout=45

# Simple AI Configuration (always available fallback)
ai.simple.enabled=true
ai.simple.timeout=5
ai.simple.responses.cache=true

# CI Environment Specific Settings
ai.test.mode=fallback
ai.test.ci.enabled=true
ai.test.retry.attempts=3
ai.test.retry.delay=2

# Self-Healing Configuration
ai.healing.enabled=true
ai.healing.cache=true
ai.healing.max.attempts=5
ai.healing.timeout=15

# Logging Configuration
ai.logging.level=INFO
ai.logging.performance=true
ai.logging.ci.verbose=true